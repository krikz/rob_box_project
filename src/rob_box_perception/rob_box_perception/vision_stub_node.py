#!/usr/bin/env python3
"""
vision_stub_node.py - –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è Vision Context

–í—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–æ–¥–∞, –∫–æ—Ç–æ—Ä–∞—è –ø—É–±–ª–∏–∫—É–µ—Ç —Ñ–µ–π–∫–æ–≤—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
–≤–º–µ—Å—Ç–æ —Ä–µ–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

–í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç:
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ AI HAT 26 TOPS
- YOLO –¥–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
- –ê–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞–º–µ—Ä (front stereo, up camera)

–°–µ–π—á–∞—Å:
- –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –Ω–∞ /oak/rgb/image_raw/compressed
- –ü—É–±–ª–∏–∫—É–µ—Ç /perception/vision_context —Å –∑–∞–≥–ª—É—à–∫–æ–π
"""

import json
import time

import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from sensor_msgs.msg import CompressedImage


class VisionStubNode(Node):
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è vision processing"""
    
    def __init__(self):
        super().__init__('vision_stub_node')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.declare_parameter('publish_rate', 1.0)  # Hz
        self.publish_rate = self.get_parameter('publish_rate').value
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.frame_count = 0
        self.last_frame_time = None
        
        # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –∫–∞–º–µ—Ä—É
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: OAK-D –ø—É–±–ª–∏–∫—É–µ—Ç –≤ /camera/rgb/..., –∞ –Ω–µ /oak/rgb/...
        self.camera_sub = self.create_subscription(
            CompressedImage,
            '/camera/rgb/image_raw/compressed',
            self.on_camera_frame,
            10
        )
        
        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        self.context_pub = self.create_publisher(
            String,
            '/perception/vision_context',
            10
        )
        
        # –¢–∞–π–º–µ—Ä –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∫–∞–º–µ—Ä—ã)
        timer_period = 1.0 / self.publish_rate
        self.timer = self.create_timer(timer_period, self.publish_context)
        
        self.get_logger().info('üëÅÔ∏è  Vision Stub Node –∑–∞–ø—É—â–µ–Ω')
        self.get_logger().info(f'   –ß–∞—Å—Ç–æ—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {self.publish_rate} Hz')
        self.get_logger().warn('‚ö†Ô∏è  –≠—Ç–æ –ó–ê–ì–õ–£–®–ö–ê! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ AI HAT + YOLO –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    
    def on_camera_frame(self, msg: CompressedImage):
        """–ü–æ–ª—É—á–µ–Ω –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã"""
        self.frame_count += 1
        self.last_frame_time = time.time()
        
        # –í —Ä–µ–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç:
        # 1. –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ JPEG
        # 2. Inference –Ω–∞ AI HAT (YOLO)
        # 3. –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # 4. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        if self.frame_count % 30 == 0:  # –ö–∞–∂–¥—ã–µ 30 –∫–∞–¥—Ä–æ–≤
            self.get_logger().debug(f'üì∏ –ü–æ–ª—É—á–µ–Ω–æ {self.frame_count} –∫–∞–¥—Ä–æ–≤')
    
    def publish_context(self):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–°–¢–ê–ë)"""
        # –§–µ–π–∫–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        context = {
            'timestamp': time.time(),
            'camera': 'oak-d-front-stereo',
            'frame_count': self.frame_count,
            'camera_active': self.last_frame_time is not None,
            'objects': [
                # –ü–æ–∫–∞ –ø—É—Å—Ç–æ - –≤ –±—É–¥—É—â–µ–º YOLO –¥–µ—Ç–µ–∫—Ü–∏–∏
                # {'type': 'person', 'confidence': 0.95, 'bbox': [x, y, w, h]},
                # {'type': 'chair', 'confidence': 0.87, 'bbox': [x, y, w, h]},
            ],
            'description': '–ó–∞–≥–ª—É—à–∫–∞: –∫–∞–º–µ—Ä–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∂–¥—ë–º AI HAT + YOLO',
            'note': 'TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–∞ AI HAT —Å YOLO v8/v11'
        }
        
        # –ï—Å–ª–∏ –∫–∞–º–µ—Ä–∞ –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∞ –∫–∞–¥—Ä—ã
        if self.last_frame_time:
            elapsed = time.time() - self.last_frame_time
            if elapsed < 5.0:  # –ö–∞–¥—Ä—ã –±—ã–ª–∏ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–µ–∫—É–Ω–¥
                context['camera_active'] = True
                context['last_frame_ago'] = f'{elapsed:.1f}s'
            else:
                context['camera_active'] = False
                context['description'] = '–ö–∞–º–µ—Ä–∞ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞–¥—Ä—ã'
        
        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è
        msg = String()
        msg.data = json.dumps(context, ensure_ascii=False)
        self.context_pub.publish(msg)
        
        if self.frame_count % 10 == 0:
            self.get_logger().debug(
                f'üì§ Vision context: frames={self.frame_count}, '
                f'active={context["camera_active"]}'
            )


def main(args=None):
    rclpy.init(args=args)
    node = VisionStubNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
