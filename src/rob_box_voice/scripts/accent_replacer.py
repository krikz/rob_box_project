#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∏ —É–¥–∞—Ä–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ
–Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–≤–∞—Ä—è –∑–∞–º–µ–Ω
"""

import json
import os
import re
from typing import Dict


class AccentReplacer:
    """–ó–∞–º–µ–Ω—è–µ—Ç —Å–ª–æ–≤–∞ –Ω–∞ –≤–µ—Ä—Å–∏–∏ —Å —É–¥–∞—Ä–µ–Ω–∏—è–º–∏"""
    
    def __init__(self, config_path: str = None):
        if config_path is None:
            config_path = os.path.join(
                os.path.dirname(__file__),
                '../config/accent_replacements.json'
            )
        
        self.replacements = self._load_config(config_path)
        self.word_dict = self._build_word_dict()
    
    def _load_config(self, path: str) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥ —Å –∑–∞–º–µ–Ω–∞–º–∏"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"‚ö†Ô∏è  –§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å")
            return {}
    
    def _build_word_dict(self) -> Dict[str, str]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –ø–ª–æ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –≤—Å–µ—Ö –∑–∞–º–µ–Ω"""
        word_dict = {}
        
        for category, words in self.replacements.items():
            if category.startswith('_'):
                continue
            
            if category == 'homographs':
                # –û–º–æ–≥—Ä–∞—Ñ—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
                continue
            
            if isinstance(words, dict):
                word_dict.update(words)
        
        return word_dict
    
    def add_accents(self, text: str) -> str:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —É–¥–∞—Ä–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç
        
        Args:
            text: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            —Ç–µ–∫—Å—Ç —Å —É–¥–∞—Ä–µ–Ω–∏—è–º–∏
        """
        result = text
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã (—Å–ª–æ–≤–æ —Ü–µ–ª–∏–∫–æ–º)
        for word_no_accent, word_with_accent in self.word_dict.items():
            # –ò—â–µ–º —Å–ª–æ–≤–æ —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ (–Ω–µ —á–∞—Å—Ç—å –¥—Ä—É–≥–æ–≥–æ —Å–ª–æ–≤–∞)
            pattern = r'\b' + re.escape(word_no_accent) + r'\b'
            result = re.sub(pattern, word_with_accent, result, flags=re.IGNORECASE)
        
        # TODO: –û–º–æ–≥—Ä–∞—Ñ—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–ø–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
        
        return result
    
    def get_stats(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–ª–æ–≤–∞—Ä—è"""
        stats = {
            'total_words': len(self.word_dict),
            'categories': {}
        }
        
        for category, words in self.replacements.items():
            if category.startswith('_'):
                continue
            
            if category == 'homographs':
                stats['categories'][category] = len(words)
            elif isinstance(words, dict):
                stats['categories'][category] = len(words)
        
        return stats


if __name__ == "__main__":
    # –¢–µ—Å—Ç
    replacer = AccentReplacer()
    
    print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–≤–∞—Ä—è:")
    print(json.dumps(replacer.get_stats(), indent=2, ensure_ascii=False))
    
    print("\nüß™ –¢–µ—Å—Ç—ã:")
    
    test_cases = [
        "–ü—Ä–∏–≤–µ—Ç! –Ø —Ä–æ–±–æ—Ç –†–û–ë–ë–û–ö–° –∏–∑ –≥–æ—Ä–æ–¥–∞ –°–æ—á–∏.",
        "–¢–µ–æ—Ä–µ–º–∞ –ü–∏—Ñ–∞–≥–æ—Ä–∞ –≥–ª–∞—Å–∏—Ç: –∫–≤–∞–¥—Ä–∞—Ç –≥–∏–ø–æ—Ç–µ–Ω—É–∑—ã.",
        "–ì–æ—Ä–æ–¥ –ú–æ—Å–∫–≤–∞ - —Å—Ç–æ–ª–∏—Ü–∞ –†–æ—Å—Å–∏–∏.",
        "–°–∏—Å—Ç–µ–º–∞ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ —Å –ª–∏–¥–∞—Ä–æ–º —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ.",
        "–ë–∞—Ç–∞—Ä–µ—è –∑–∞—Ä—è–∂–µ–Ω–∞ –Ω–∞ –≤–æ—Å–µ–º—å–¥–µ—Å—è—Ç –ø—Ä–æ—Ü–µ–Ω—Ç."
    ]
    
    for test in test_cases:
        result = replacer.add_accents(test)
        print(f"\n–ò—Å—Ö–æ–¥–Ω—ã–π: {test}")
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
