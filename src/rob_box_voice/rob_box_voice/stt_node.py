#!/usr/bin/env python3
"""
STTNode - Speech-to-Text —Å Yandex STT gRPC v3 (primary) + Vosk (fallback)
–ü–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è: /audio/speech_audio (AudioData)
–ü—É–±–ª–∏–∫—É–µ—Ç: /voice/stt/result (String)
"""

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, DurabilityPolicy
from std_msgs.msg import String
from audio_common_msgs.msg import AudioData

import json
import os
from typing import Optional
from vosk import Model, KaldiRecognizer
import grpc
import numpy as np

# Yandex Cloud STT API v3 (gRPC)
try:
    from yandex.cloud.ai.stt.v3 import stt_pb2, stt_service_pb2_grpc
    YANDEX_GRPC_AVAILABLE = True
except ImportError:
    YANDEX_GRPC_AVAILABLE = False
    print("‚ö†Ô∏è  yandex-cloud-ml-sdk –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Vosk.")


class STTNode(Node):
    """–ù–æ–¥–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: Yandex STT gRPC v3 (primary) + Vosk (fallback)"""
    
    def __init__(self):
        super().__init__('stt_node')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Vosk (fallback)
        self.declare_parameter('model_path', '/models/vosk-model-small-ru-0.22')
        self.declare_parameter('sample_rate', 16000)
        
        self.model_path = self.get_parameter('model_path').value
        self.sample_rate = self.get_parameter('sample_rate').value
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Yandex STT (primary)
        self.declare_parameter('yandex_api_key', '')
        self.declare_parameter('yandex_language', 'ru-RU')
        self.declare_parameter('yandex_model', 'general')
        
        self.yandex_api_key = self.get_parameter('yandex_api_key').value or os.environ.get('YANDEX_API_KEY', '')
        self.yandex_language = self.get_parameter('yandex_language').value
        self.yandex_model = self.get_parameter('yandex_model').value
        
        # Yandex gRPC –∫–ª–∏–µ–Ω—Ç
        self.yandex_channel = None
        self.yandex_stub = None
        
        # QoS –¥–ª—è –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞
        audio_qos = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            durability=DurabilityPolicy.VOLATILE,
            depth=10
        )
        
        # Subscriber - —Å–ª—É—à–∞–µ–º —Ç–æ–ª—å–∫–æ speech_audio (—É–∂–µ –≥–æ—Ç–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã)
        self.audio_sub = self.create_subscription(
            AudioData,
            '/audio/speech_audio',
            self.speech_audio_callback,
            audio_qos
        )
        
        # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ TTS (—á—Ç–æ–±—ã –Ω–µ —Å–ª—ã—à–∞—Ç—å —Å–µ–±—è)
        self.tts_state_sub = self.create_subscription(
            String,
            '/voice/tts/state',
            self.tts_state_callback,
            10
        )
        
        # Publishers
        self.result_pub = self.create_publisher(String, '/voice/stt/result', 10)
        self.state_pub = self.create_publisher(String, '/voice/stt/state', 10)
        
        # Vosk –º–æ–¥–µ–ª—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å
        self.model: Optional[Model] = None
        self.recognizer: Optional[KaldiRecognizer] = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_robot_speaking = False  # –§–ª–∞–≥: —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç (–Ω–µ —Å–ª—É—à–∞—Ç—å!)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.get_logger().info('STTNode –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω')
        self.initialize_yandex()
        self.initialize_vosk()
    
    def initialize_yandex(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Yandex STT gRPC v3"""
        if not YANDEX_GRPC_AVAILABLE:
            self.get_logger().warn('‚ö†Ô∏è  Yandex Cloud ML SDK –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Vosk')
            return
        
        if not self.yandex_api_key:
            self.get_logger().warn('‚ö†Ô∏è  YANDEX_API_KEY –Ω–µ –∑–∞–¥–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Vosk')
            return
        
        try:
            self.get_logger().info('üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Yandex STT gRPC v3...')
            self.yandex_channel = grpc.secure_channel(
                'stt.api.cloud.yandex.net:443',
                grpc.ssl_channel_credentials()
            )
            self.yandex_stub = stt_service_pb2_grpc.RecognizerStub(self.yandex_channel)
            self.get_logger().info(f'‚úÖ Yandex STT gRPC v3 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (—è–∑—ã–∫: {self.yandex_language})')
        except Exception as e:
            self.get_logger().error(f'‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Yandex STT: {e}')
            self.yandex_stub = None
    
    def initialize_vosk(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ Vosk –º–æ–¥–µ–ª–∏ (fallback)"""
        try:
            self.get_logger().info(f'–ó–∞–≥—Ä—É–∑–∫–∞ Vosk –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}...')
            self.model = Model(self.model_path)
            self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
            self.recognizer.SetWords(True)  # –ü–æ–ª—É—á–∞—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –ø–æ —Å–ª–æ–≤–∞–º
            self.get_logger().info('‚úÖ Vosk –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (fallback)')
            self.publish_state('ready')
        except Exception as e:
            self.get_logger().error(f'‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Vosk: {e}')
            self.publish_state('error')
    
    def tts_state_callback(self, msg: String):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è TTS - –Ω–µ —Å–ª—É—à–∞—Ç—å –∫–æ–≥–¥–∞ —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç!"""
        if msg.data in ['synthesizing', 'playing']:
            if not self.is_robot_speaking:
                self.get_logger().info('üîá –†–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ')
                self.is_robot_speaking = True
        elif msg.data in ['ready', 'idle']:
            if self.is_robot_speaking:
                self.get_logger().info('üéôÔ∏è –†–æ–±–æ—Ç –∑–∞–º–æ–ª—á–∞–ª - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ')
                self.is_robot_speaking = False
    
    def speech_audio_callback(self, msg: AudioData):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–∑ –æ—Ç audio_node
        –ü—Ä–æ–±—É–µ–º Yandex STT ‚Üí –µ—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º Vosk
        """
        # –ù–ï –°–õ–£–®–ê–¢–¨ –∫–æ–≥–¥–∞ —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç (—Å–∞–º–æ–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ!)
        if self.is_robot_speaking:
            self.get_logger().info('üîá –ò–≥–Ω–æ—Ä: —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç')
            return
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –≤ bytes
        audio_bytes = bytes(msg.data)
        duration = len(audio_bytes) / (self.sample_rate * 2)  # 16-bit = 2 bytes
        
        self.get_logger().info(f'üé§ –ü–æ–ª—É—á–µ–Ω–∞ —Ñ—Ä–∞–∑–∞: {duration:.2f}—Å ({len(audio_bytes)} bytes)')
        self.publish_state('recognizing')
        
        text = None
        
        # 1. –ü–æ–ø—ã—Ç–∫–∞ Yandex STT (primary)
        if self.yandex_stub:
            try:
                text = self._recognize_yandex(audio_bytes)
                if text:
                    self.get_logger().info(f'‚úÖ Yandex STT: "{text}"')
            except Exception as e:
                self.get_logger().error(f'‚ö†Ô∏è  Yandex STT –æ—à–∏–±–∫–∞: {e}, fallback –Ω–∞ Vosk')
        
        # 2. Fallback –Ω–∞ Vosk –µ—Å–ª–∏ Yandex –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
        if not text and self.recognizer:
            text = self._recognize_vosk(audio_bytes)
            if text:
                self.get_logger().info(f'‚úÖ Vosk (fallback): "{text}"')
        
        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if text and len(text) >= 3:
            self.get_logger().info(f'‚úÖ –ü–†–ò–ù–Ø–¢–û: {text}')
            self.publish_result(text)
            self.publish_state('ready')
        elif text:
            self.get_logger().warn(f'‚ùå –û–¢–ö–õ–û–ù–ï–ù–û (–∫–æ—Ä–æ—Ç–∫–æ–µ): "{text}"')
            self.publish_state('ready')
        else:
            self.get_logger().warn(f'‚ùå –û–¢–ö–õ–û–ù–ï–ù–û (–ø—É—Å—Ç–æ–µ)')
            self.publish_state('ready')
    
    def _recognize_yandex(self, audio_bytes: bytes) -> Optional[str]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Yandex Cloud STT gRPC v3 (RecognizeFile API)
        """
        # –°–æ–∑–¥–∞—ë–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        recognize_request = stt_pb2.RecognizeFileRequest(
            # content - –ø—Ä—è–º–æ bytes
            content=audio_bytes,
            # recognition_model —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∫–ª—é—á–∞—è audio_format
            recognition_model=stt_pb2.RecognitionModelOptions(
                model=self.yandex_model,
                audio_format=stt_pb2.AudioFormatOptions(
                    raw_audio=stt_pb2.RawAudio(
                        audio_encoding=stt_pb2.RawAudio.LINEAR16_PCM,
                        sample_rate_hertz=self.sample_rate,
                        audio_channel_count=1
                    )
                ),
                language_restriction=stt_pb2.LanguageRestrictionOptions(
                    restriction_type=stt_pb2.LanguageRestrictionOptions.WHITELIST,
                    language_code=[self.yandex_language]
                ),
                audio_processing_type=stt_pb2.RecognitionModelOptions.REAL_TIME
            )
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
        response = self.yandex_stub.RecognizeFile(
            recognize_request,
            metadata=(('authorization', f'Api-Key {self.yandex_api_key}'),)
        )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
        # RecognizeFileResponse —Å–æ–¥–µ—Ä–∂–∏—Ç text –∏–ª–∏ chunks —Å alternatives
        if response:
            # –ü–æ–ø—ã—Ç–∫–∞ 1: text –Ω–∞–ø—Ä—è–º—É—é
            if hasattr(response, 'text') and response.text:
                return response.text.strip()
            # –ü–æ–ø—ã—Ç–∫–∞ 2: chunks[].alternatives[].text
            if hasattr(response, 'chunks') and len(response.chunks) > 0:
                for chunk in response.chunks:
                    if hasattr(chunk, 'alternatives') and len(chunk.alternatives) > 0:
                        text = chunk.alternatives[0].text.strip()
                        if text:
                            return text
        
        return None
    
    def _recognize_vosk(self, audio_bytes: bytes) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Vosk (fallback)"""
        if self.recognizer.AcceptWaveform(audio_bytes):
            result = json.loads(self.recognizer.Result())
        else:
            result = json.loads(self.recognizer.FinalResult())
        
        text = result.get('text', '').strip()
        
        # –°–±—Ä–æ—Å–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Ñ—Ä–∞–∑—ã
        self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
        self.recognizer.SetWords(True)
        
        return text
    
    def publish_result(self, text: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        msg = String()
        msg.data = text
        self.result_pub.publish(msg)
        self.get_logger().info(f'üì§ –û–ø—É–±–ª–∏–∫–æ–≤–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {text}')
    
    def publish_state(self, state: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–æ–¥—ã"""
        msg = String()
        msg.data = state
        self.state_pub.publish(msg)


def main(args=None):
    rclpy.init(args=args)
    node = STTNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
