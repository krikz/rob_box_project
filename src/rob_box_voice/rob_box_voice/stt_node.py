#!/usr/bin/env python3
"""
STTNode - Speech-to-Text —Å Yandex STT gRPC v3 (primary) + Vosk (fallback)
–ü–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è: /audio/speech_audio (AudioData)
–ü—É–±–ª–∏–∫—É–µ—Ç: /voice/stt/result (String)
"""

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, DurabilityPolicy
from std_msgs.msg import String
from audio_common_msgs.msg import AudioData

import json
import os
from typing import Optional
from vosk import Model, KaldiRecognizer
import grpc
import numpy as np

# Yandex Cloud STT API v3 (gRPC)
try:
    from yandex.cloud.ai.stt.v3 import stt_pb2, stt_service_pb2_grpc
    YANDEX_GRPC_AVAILABLE = True
except ImportError:
    YANDEX_GRPC_AVAILABLE = False
    print("‚ö†Ô∏è  yandex-cloud-ml-sdk –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Vosk.")


class STTNode(Node):
    """–ù–æ–¥–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: Yandex STT gRPC v3 (primary) + Vosk (fallback)"""
    
    def __init__(self):
        super().__init__('stt_node')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Vosk (fallback)
        self.declare_parameter('model_path', '/models/vosk-model-small-ru-0.22')
        self.declare_parameter('sample_rate', 16000)
        
        self.model_path = self.get_parameter('model_path').value
        self.sample_rate = self.get_parameter('sample_rate').value
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Yandex STT (primary)
        self.declare_parameter('yandex_api_key', '')
        self.declare_parameter('yandex_language', 'ru-RU')
        self.declare_parameter('yandex_model', 'general')
        
        self.yandex_api_key = self.get_parameter('yandex_api_key').value or os.environ.get('YANDEX_API_KEY', '')
        self.yandex_language = self.get_parameter('yandex_language').value
        self.yandex_model = self.get_parameter('yandex_model').value
        
        # Yandex gRPC –∫–ª–∏–µ–Ω—Ç
        self.yandex_channel = None
        self.yandex_stub = None
        
        # QoS –¥–ª—è –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞
        audio_qos = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            durability=DurabilityPolicy.VOLATILE,
            depth=10
        )
        
        # Subscriber - —Å–ª—É—à–∞–µ–º —Ç–æ–ª—å–∫–æ speech_audio (—É–∂–µ –≥–æ—Ç–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã)
        self.audio_sub = self.create_subscription(
            AudioData,
            '/audio/speech_audio',
            self.speech_audio_callback,
            audio_qos
        )
        
        # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ TTS (—á—Ç–æ–±—ã –Ω–µ —Å–ª—ã—à–∞—Ç—å —Å–µ–±—è)
        self.tts_state_sub = self.create_subscription(
            String,
            '/voice/tts/state',
            self.tts_state_callback,
            10
        )
        
        # Publishers
        self.result_pub = self.create_publisher(String, '/voice/stt/result', 10)
        self.state_pub = self.create_publisher(String, '/voice/stt/state', 10)
        
        # Vosk –º–æ–¥–µ–ª—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å
        self.model: Optional[Model] = None
        self.recognizer: Optional[KaldiRecognizer] = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_robot_speaking = False  # –§–ª–∞–≥: —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç (–Ω–µ —Å–ª—É—à–∞—Ç—å!)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.get_logger().info('STTNode –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω')
        self.initialize_yandex()
        self.initialize_vosk()
    
    def initialize_yandex(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Yandex STT gRPC v3"""
        if not YANDEX_GRPC_AVAILABLE:
            self.get_logger().warn('‚ö†Ô∏è  Yandex Cloud ML SDK –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Vosk')
            return
        
        if not self.yandex_api_key:
            self.get_logger().warn('‚ö†Ô∏è  YANDEX_API_KEY –Ω–µ –∑–∞–¥–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Vosk')
            return
        
        try:
            self.get_logger().info('üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Yandex STT gRPC v3...')
            self.yandex_channel = grpc.secure_channel(
                'stt.api.cloud.yandex.net:443',
                grpc.ssl_channel_credentials()
            )
            self.yandex_stub = stt_service_pb2_grpc.RecognizerStub(self.yandex_channel)
            self.get_logger().info(f'‚úÖ Yandex STT gRPC v3 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (—è–∑—ã–∫: {self.yandex_language})')
        except Exception as e:
            self.get_logger().error(f'‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Yandex STT: {e}')
            self.yandex_stub = None
    
    def initialize_vosk(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ Vosk –º–æ–¥–µ–ª–∏ (fallback)"""
        try:
            self.get_logger().info(f'–ó–∞–≥—Ä—É–∑–∫–∞ Vosk –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}...')
            self.model = Model(self.model_path)
            self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
            self.recognizer.SetWords(True)  # –ü–æ–ª—É—á–∞—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –ø–æ —Å–ª–æ–≤–∞–º
            self.get_logger().info('‚úÖ Vosk –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (fallback)')
            self.publish_state('ready')
        except Exception as e:
            self.get_logger().error(f'‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Vosk: {e}')
            self.publish_state('error')
    
    def tts_state_callback(self, msg: String):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è TTS - –Ω–µ —Å–ª—É—à–∞—Ç—å –∫–æ–≥–¥–∞ —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç!"""
        if msg.data in ['synthesizing', 'playing']:
            if not self.is_robot_speaking:
                self.get_logger().info('üîá –†–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ')
                self.is_robot_speaking = True
        elif msg.data in ['ready', 'idle']:
            if self.is_robot_speaking:
                self.get_logger().info('üéôÔ∏è –†–æ–±–æ—Ç –∑–∞–º–æ–ª—á–∞–ª - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ')
                self.is_robot_speaking = False
    
    def speech_audio_callback(self, msg: AudioData):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–∑ –æ—Ç audio_node
        –ü—Ä–æ–±—É–µ–º Yandex STT ‚Üí –µ—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º Vosk
        """
        # –ù–ï –°–õ–£–®–ê–¢–¨ –∫–æ–≥–¥–∞ —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç (—Å–∞–º–æ–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ!)
        if self.is_robot_speaking:
            self.get_logger().info('üîá –ò–≥–Ω–æ—Ä: —Ä–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç')
            return
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –≤ bytes
        audio_bytes = bytes(msg.data)
        duration = len(audio_bytes) / (self.sample_rate * 2)  # 16-bit = 2 bytes
        
        self.get_logger().info(f'üé§ –ü–æ–ª—É—á–µ–Ω–∞ —Ñ—Ä–∞–∑–∞: {duration:.2f}—Å ({len(audio_bytes)} bytes)')
        self.publish_state('recognizing')
        
        text = None
        
        # 1. –ü–æ–ø—ã—Ç–∫–∞ Yandex STT (primary)
        if self.yandex_stub:
            try:
                text = self._recognize_yandex(audio_bytes)
                if text:
                    self.get_logger().info(f'‚úÖ Yandex STT: "{text}"')
            except Exception as e:
                self.get_logger().error(f'‚ö†Ô∏è  Yandex STT –æ—à–∏–±–∫–∞: {e}, fallback –Ω–∞ Vosk')
        
        # 2. Fallback –Ω–∞ Vosk –µ—Å–ª–∏ Yandex –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
        if not text and self.recognizer:
            text = self._recognize_vosk(audio_bytes)
            if text:
                self.get_logger().info(f'‚úÖ Vosk (fallback): "{text}"')
        
        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if text and len(text) >= 3:
            self.get_logger().info(f'‚úÖ –ü–†–ò–ù–Ø–¢–û: {text}')
            self.publish_result(text)
            self.publish_state('ready')
        elif text:
            self.get_logger().warn(f'‚ùå –û–¢–ö–õ–û–ù–ï–ù–û (–∫–æ—Ä–æ—Ç–∫–æ–µ): "{text}"')
            self.publish_state('ready')
        else:
            self.get_logger().warn(f'‚ùå –û–¢–ö–õ–û–ù–ï–ù–û (–ø—É—Å—Ç–æ–µ)')
            self.publish_state('ready')
    
    def _recognize_yandex(self, audio_bytes: bytes) -> Optional[str]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Yandex Cloud STT gRPC v3 (Streaming API)
        –ò—Å–ø–æ–ª—å–∑—É–µ–º streaming –¥–ª—è –≥–æ—Ç–æ–≤–æ–π —Ñ—Ä–∞–∑—ã
        """
        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è streaming –∑–∞–ø—Ä–æ—Å–∞
        def gen():
            # 1. –ü–µ—Ä–≤—ã–º yield –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º session options
            recognize_options = stt_pb2.StreamingOptions(
                recognition_model=stt_pb2.RecognitionModelOptions(
                    model=self.yandex_model,
                    audio_format=stt_pb2.AudioFormatOptions(
                        raw_audio=stt_pb2.RawAudio(
                            audio_encoding=stt_pb2.RawAudio.LINEAR16_PCM,
                            sample_rate_hertz=self.sample_rate,
                            audio_channel_count=1
                        )
                    ),
                    text_normalization=stt_pb2.TextNormalizationOptions(
                        text_normalization=stt_pb2.TextNormalizationOptions.TEXT_NORMALIZATION_ENABLED,
                        profanity_filter=False,
                        literature_text=False
                    ),
                    language_restriction=stt_pb2.LanguageRestrictionOptions(
                        restriction_type=stt_pb2.LanguageRestrictionOptions.WHITELIST,
                        language_code=[self.yandex_language]
                    ),
                    audio_processing_type=stt_pb2.RecognitionModelOptions.REAL_TIME
                ),
                # –í–ê–ñ–ù–û! –ù–∞—Å—Ç—Ä–æ–π–∫–∞ EOU (End of Utterance) - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ü–∞ —Ñ—Ä–∞–∑—ã
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º max_pause_between_words_hint_ms —á—Ç–æ–±—ã —Ä–æ–±–æ—Ç –Ω–µ –æ–±—Ä—ã–≤–∞–ª —Ä–µ—á—å
                # –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–µ–¥–ª–µ–Ω–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç –∏–ª–∏ –¥–µ–ª–∞–µ—Ç –ø–∞—É–∑—ã –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏
                eou_classifier=stt_pb2.EouClassifierOptions(
                    default_classifier=stt_pb2.DefaultEouClassifier(
                        type=stt_pb2.DefaultEouClassifier.DEFAULT,  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π (DEFAULT) vs –±—ã—Å—Ç—Ä—ã–π (HIGH)
                        max_pause_between_words_hint_ms=1200  # 1.2 —Å–µ–∫ –ø–∞—É–∑—ã –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ (default ~700ms)
                    )
                )
            )
            yield stt_pb2.StreamingRequest(session_options=recognize_options)
            
            # 2. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∞–º–∏ –ø–æ 4096 –±–∞–π—Ç
            chunk_size = 4096
            for i in range(0, len(audio_bytes), chunk_size):
                chunk = audio_bytes[i:i + chunk_size]
                yield stt_pb2.StreamingRequest(chunk=stt_pb2.AudioChunk(data=chunk))
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º streaming –∑–∞–ø—Ä–æ—Å
        responses = self.yandex_stub.RecognizeStreaming(
            gen(),
            metadata=(('authorization', f'Api-Key {self.yandex_api_key}'),)
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã
        final_text = None
        for response in responses:
            event_type = response.WhichOneof('Event')
            
            # partial - –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º)
            if event_type == 'partial':
                continue
            
            # final - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            elif event_type == 'final':
                if response.final.alternatives:
                    final_text = response.final.alternatives[0].text
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —á–∏—Ç–∞—Ç—å –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ final_refinement
            
            # final_refinement - —É–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
            elif event_type == 'final_refinement':
                if response.final_refinement.normalized_text:
                    final_text = response.final_refinement.normalized_text.alternatives[0].text
                    break  # –≠—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        
        return final_text.strip() if final_text else None
    
    def _recognize_vosk(self, audio_bytes: bytes) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Vosk (fallback)"""
        if self.recognizer.AcceptWaveform(audio_bytes):
            result = json.loads(self.recognizer.Result())
        else:
            result = json.loads(self.recognizer.FinalResult())
        
        text = result.get('text', '').strip()
        
        # –°–±—Ä–æ—Å–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Ñ—Ä–∞–∑—ã
        self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
        self.recognizer.SetWords(True)
        
        return text
    
    def publish_result(self, text: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        msg = String()
        msg.data = text
        self.result_pub.publish(msg)
        self.get_logger().info(f'üì§ –û–ø—É–±–ª–∏–∫–æ–≤–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {text}')
    
    def publish_state(self, state: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–æ–¥—ã"""
        msg = String()
        msg.data = state
        self.state_pub.publish(msg)


def main(args=None):
    rclpy.init(args=args)
    node = STTNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
