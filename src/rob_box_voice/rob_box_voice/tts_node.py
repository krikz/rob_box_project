#!/usr/bin/env python3
"""
TTSNode - Text-to-Speech —Å Silero TTS v4

–ü–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –Ω–∞: /voice/dialogue/response (JSON chunks)
–ü—É–±–ª–∏–∫—É–µ—Ç: /voice/audio/speech (AudioData)
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç: Silero TTS v4 (aidar, baya, kseniya, xenia)
"""

import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from audio_common_msgs.msg import AudioData
import json
import torch
import sounddevice as sd
import numpy as np
from typing import Optional
import sys
import os
from pathlib import Path
from contextlib import contextmanager


@contextmanager
def ignore_stderr(enable=True):
    """–ü–æ–¥–∞–≤–∏—Ç—å ALSA –æ—à–∏–±–∫–∏ –æ—Ç sounddevice"""
    if enable:
        devnull = None
        try:
            devnull = os.open(os.devnull, os.O_WRONLY)
            stderr = os.dup(2)
            sys.stderr.flush()
            os.dup2(devnull, 2)
            try:
                yield
            finally:
                os.dup2(stderr, 2)
                os.close(stderr)
        finally:
            if devnull is not None:
                os.close(devnull)
    else:
        yield

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º text_normalizer
scripts_path = Path(__file__).parent.parent / 'scripts'
sys.path.insert(0, str(scripts_path))

try:
    from text_normalizer import normalize_for_tts
except ImportError:
    def normalize_for_tts(text):
        """Fallback –µ—Å–ª–∏ –Ω–µ—Ç normalizer"""
        return text


class TTSNode(Node):
    """ROS2 –Ω–æ–¥–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —Å Silero TTS"""
    
    def __init__(self):
        super().__init__('tts_node')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.declare_parameter('speaker', 'aidar')  # aidar, baya, kseniya, xenia
        self.declare_parameter('sample_rate', 24000)
        self.declare_parameter('chipmunk_mode', True)
        self.declare_parameter('pitch_shift', 1.5)  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è playback rate (1.5x = —É–º–µ—Ä–µ–Ω–Ω–æ –±—ã—Å—Ç—Ä–æ)
        # prosody_rate –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—É—é —Å–∫–æ—Ä–æ—Å—Ç—å, —É—Å–∫–æ—Ä—è–µ–º –ø—Ä–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–∏
        self.declare_parameter('prosody_pitch', 'medium')  # x-low, low, medium, high, x-high
        self.declare_parameter('normalize_text', True)
        self.declare_parameter('volume_db', -3.0)  # –ì—Ä–æ–º–∫–æ—Å—Ç—å –≤ dB (-3dB = 70%, –∫–æ–º–ø—Ä–æ–º–∏—Å—Å —Å —à—É–º–æ–º)
        
        self.speaker = self.get_parameter('speaker').value
        self.sample_rate = self.get_parameter('sample_rate').value
        self.chipmunk_mode = self.get_parameter('chipmunk_mode').value
        self.pitch_shift = self.get_parameter('pitch_shift').value
        # prosody_rate –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º - —É—Å–∫–æ—Ä—è–µ–º –ø—Ä–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–∏, –∞ –Ω–µ –≤ TTS
        self.prosody_pitch = self.get_parameter('prosody_pitch').value
        self.normalize_text = self.get_parameter('normalize_text').value
        self.volume_db = self.get_parameter('volume_db').value
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º dB –≤ –ª–∏–Ω–µ–π–Ω—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å
        # dB = 20 * log10(gain)  =>  gain = 10^(dB/20)
        self.volume_gain = 10.0 ** (self.volume_db / 20.0)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ Silero TTS
        self.get_logger().info('üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Silero TTS v4...')
        self.device = torch.device('cpu')
        
        # ‚ö° –ö–†–ò–¢–ò–ß–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø ARM64! ‚ö°
        # –ò–∑ —Å—Ç–∞—Ç—å–∏: https://habr.com/ru/companies/timeweb/articles/817929/
        torch.set_num_threads(4)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è ARM64
        torch._C._jit_set_profiling_mode(False)  # –û—Ç–∫–ª—é—á–∏—Ç—å JIT –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        torch.set_grad_enabled(False)  # –û—Ç–∫–ª—é—á–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã (—Ç–æ–ª—å–∫–æ inference)
        
        try:
            self.model, _ = torch.hub.load(
                repo_or_dir='snakers4/silero-models',
                model='silero_tts',
                language='ru',
                speaker='v4_ru'
            )
            self.model.to(self.device)
            self.get_logger().info('‚úÖ Silero TTS –∑–∞–≥—Ä—É–∂–µ–Ω (ARM64 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)')
        except Exception as e:
            self.get_logger().error(f'‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Silero: {e}')
            raise
        
        # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ dialogue response
        self.dialogue_sub = self.create_subscription(
            String,
            '/voice/dialogue/response',
            self.dialogue_callback,
            10
        )
        
        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∞—É–¥–∏–æ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.audio_pub = self.create_publisher(AudioData, '/voice/audio/speech', 10)
        self.state_pub = self.create_publisher(String, '/voice/tts/state', 10)
        
        # –ü—É–±–ª–∏–∫—É–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.publish_state('ready')
        
        self.get_logger().info('‚úÖ TTSNode –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω')
        self.get_logger().info(f'  Speaker: {self.speaker}')
        self.get_logger().info(f'  Sample rate: {self.sample_rate} Hz')
        self.get_logger().info(f'  Volume: {self.volume_db:.1f} dB (gain: {self.volume_gain:.2f}x)')
        self.get_logger().info(f'  Chipmunk mode: {self.chipmunk_mode}')
        if self.chipmunk_mode:
            self.get_logger().info(f'  Pitch shift: {self.pitch_shift}x (—É—Å–∫–æ—Ä—è–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ)')
            self.get_logger().info(f'  Prosody: pitch={self.prosody_pitch} (rate –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è!)')
    
    def dialogue_callback(self, msg: String):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ JSON chunks –æ—Ç dialogue_node"""
        try:
            chunk_data = json.loads(msg.data)
            
            if 'ssml' not in chunk_data:
                self.get_logger().warn('‚ö† Chunk –±–µ–∑ SSML')
                return
            
            ssml = chunk_data['ssml']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ SSML
            text = self._extract_text_from_ssml(ssml)
            
            if not text.strip():
                return
            
            self.get_logger().info(f'üîä TTS: {text[:50]}...')
            
            # –°–∏–Ω—Ç–µ–∑ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
            self._synthesize_and_play(ssml, text)
            
        except json.JSONDecodeError as e:
            self.get_logger().error(f'‚ùå JSON parse error: {e}')
        except Exception as e:
            self.get_logger().error(f'‚ùå TTS error: {e}')
    
    def _extract_text_from_ssml(self, ssml: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ SSML —Ç–µ–≥–æ–≤"""
        import re
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ XML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', ssml)
        return text.strip()
    
    def _synthesize_and_play(self, ssml: str, text: str):
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ"""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        if self.normalize_text:
            text = normalize_for_tts(text)
        
        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ SSML (–ë–ï–ó rate - —É—Å–∫–æ—Ä—è–µ–º –ø—Ä–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–∏!)
        if not ssml.startswith('<speak>'):
            ssml_text = f'<speak><prosody pitch="{self.prosody_pitch}">{text}</prosody></speak>'
        else:
            # –£–∂–µ –µ—Å—Ç—å SSML –æ—Ç DeepSeek, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            ssml_text = ssml
        
        try:
            # –°–∏–Ω—Ç–µ–∑
            self.publish_state('synthesizing')
            self.get_logger().info('üîä –°–∏–Ω—Ç–µ–∑–∏—Ä—É—é —Ä–µ—á—å...')
            
            audio = self.model.apply_tts(
                ssml_text=ssml_text,
                speaker=self.speaker,
                sample_rate=self.sample_rate
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
            audio_np = audio.numpy()
            self.get_logger().info(f'‚úÖ –°–∏–Ω—Ç–µ–∑ —É—Å–ø–µ—à–µ–Ω: {len(audio_np)} samples @ {self.sample_rate} Hz')
            
            # –ü—É–±–ª–∏–∫—É–µ–º –≤ ROS topic
            self._publish_audio(audio_np)
            
            # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –ª–æ–∫–∞–ª—å–Ω–æ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
            self.publish_state('playing')
            
            # –í–ê–ñ–ù–û: ReSpeaker –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¢–û–õ–¨–ö–û 16kHz —Å—Ç–µ—Ä–µ–æ!
            # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –¥–ª—è chipmunk mode –∏–ª–∏ –¥–ª—è ReSpeaker
            target_rate = 16000  # ReSpeaker —Ç—Ä–µ–±—É–µ—Ç 16kHz
            
            if self.chipmunk_mode:
                # Chipmunk: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º 24kHz, —É—Å–∫–æ—Ä—è–µ–º playback, –∑–∞—Ç–µ–º —Ä–µ—Å–µ–º–ø–ª–∏–º –¥–æ 16kHz
                playback_rate = int(self.sample_rate * self.pitch_shift)
                self.get_logger().info(f'üêøÔ∏è  –ë—É—Ä—É–Ω–¥—É–∫ —Ä–µ–∂–∏–º: {self.pitch_shift}x ‚Üí {playback_rate} Hz (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π)')
                # –°–Ω–∞—á–∞–ª–∞ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ playback_rate
                num_samples_intermediate = int(len(audio_np) * playback_rate / self.sample_rate)
                audio_intermediate = np.interp(
                    np.linspace(0, len(audio_np) - 1, num_samples_intermediate),
                    np.arange(len(audio_np)),
                    audio_np
                )
                # –ó–∞—Ç–µ–º –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–æ 16kHz –¥–ª—è ReSpeaker
                num_samples_final = int(len(audio_intermediate) * target_rate / playback_rate)
                audio_resampled = np.interp(
                    np.linspace(0, len(audio_intermediate) - 1, num_samples_final),
                    np.arange(len(audio_intermediate)),
                    audio_intermediate
                )
                self.get_logger().info(f'üîÑ –†–µ—Å–µ–º–ø–ª–∏–Ω–≥: {playback_rate} Hz ‚Üí {target_rate} Hz (ReSpeaker)')
            else:
                # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: –ø—Ä–æ—Å—Ç–æ–π —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥ —Å 24kHz –Ω–∞ 16kHz
                num_samples = int(len(audio_np) * target_rate / self.sample_rate)
                audio_resampled = np.interp(
                    np.linspace(0, len(audio_np) - 1, num_samples),
                    np.arange(len(audio_np)),
                    audio_np
                )
                self.get_logger().info(f'üîÑ –†–µ—Å–µ–º–ø–ª–∏–Ω–≥: {self.sample_rate} Hz ‚Üí {target_rate} Hz (ReSpeaker)')
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (dB ‚Üí –ª–∏–Ω–µ–π–Ω—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å)
            audio_np_adjusted = audio_resampled * self.volume_gain
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–æ–Ω–æ ‚Üí —Å—Ç–µ—Ä–µ–æ (ReSpeaker —Ç—Ä–µ–±—É–µ—Ç 2 –∫–∞–Ω–∞–ª–∞!)
            audio_stereo = np.column_stack((audio_np_adjusted, audio_np_adjusted))
            self.get_logger().info(f'üîä –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ: {len(audio_stereo)} frames, {playback_rate} Hz, —Å—Ç–µ—Ä–µ–æ')
            
            # –ë–ª–æ–∫–∏—Ä—É—é—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (—Å –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ–º ALSA –æ—à–∏–±–æ–∫)
            with ignore_stderr(enable=True):
                sd.play(audio_stereo, playback_rate, device=1, blocking=True)
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ –æ—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä—ã
                sd.stop()
                sd.wait()
            
            # –ó–∞–∫–æ–Ω—á–∏–ª–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
            self.publish_state('ready')
            self.get_logger().info('‚úÖ –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ')
            
        except Exception as e:
            self.get_logger().error(f'‚ùå Synthesis error: {e}')
            # –í–ê–ñ–ù–û: —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ is_speaking –ø—Ä–∏ –æ—à–∏–±–∫–µ!
            self.publish_state('ready')
    
    def _publish_audio(self, audio_np: np.ndarray):
        """–ü—É–±–ª–∏–∫—É–µ—Ç –∞—É–¥–∏–æ –≤ ROS topic"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int16 –¥–ª—è AudioData
        audio_int16 = (audio_np * 32767).astype(np.int16)
        
        msg = AudioData()
        msg.data = audio_int16.tobytes()
        
        self.audio_pub.publish(msg)
    
    def publish_state(self, state: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è TTS"""
        msg = String()
        msg.data = state
        self.state_pub.publish(msg)


def main(args=None):
    rclpy.init(args=args)
    node = TTSNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
