# Voice Assistant Architecture Overview

## –ü–æ–ª–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

### Nodes (8 —à—Ç—É–∫)

| # | Node | Package | –û–ø–∏—Å–∞–Ω–∏–µ | Phase |
|---|------|---------|----------|-------|
| 1 | `audio_node` | rob_box_voice | –ó–∞—Ö–≤–∞—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ | 1 |
| 2 | `led_node` | rob_box_voice | LED –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è | 1 |
| 3 | `animation_player` | rob_box_animations | –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∏–º–∞—Ü–∏–π | 1 |
| 4 | `dialogue_node` | rob_box_voice | LLM –¥–∏–∞–ª–æ–≥ (DeepSeek) | 2 |
| 5 | `tts_node` | rob_box_voice | –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ (Silero TTS) | 2 |
| 6 | `stt_node` | rob_box_voice | –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (Vosk) | 3 |
| 7 | `sound_node` | rob_box_voice | –ó–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã (MP3) | 4 |
| 8 | `command_node` | rob_box_voice | –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–æ–±–æ—Ç–æ–º (Nav2) | 5 |

### Topics Flow

```
üé§ Microphone
  ‚Üì
/voice/audio/recording (AudioData)
  ‚Üì
üó£Ô∏è STT Node
  ‚Üì
/voice/stt/result (String) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚Üì                              ‚Üì             ‚Üì
üí¨ Dialogue Node          üéØ Command Node   (Other)
  ‚Üì                              ‚Üì
  ‚îú‚Üí /voice/dialogue/response    ‚îî‚Üí NavigateToPose (Action)
  ‚îú‚Üí /voice/sound/trigger               ‚Üì
  ‚îÇ                              ü§ñ Nav2 Stack
  ‚Üì                                     ‚Üì
üîä TTS Node                       /cmd_vel (Twist)
  ‚Üì                                     ‚Üì
/voice/audio/speech (AudioData)  üéÆ Twist Mux
  ‚Üì                                     ‚Üì
üîä Audio Output                   /diff_cont/cmd_vel_unstamped
  ‚Üì                                     ‚Üì
üé§ Audio Reactive Node            ‚öôÔ∏è ros2_control
  ‚Üì                                     ‚Üì
/audio/level (Float32)            üîß VESC Motors
  ‚Üì                                     ‚Üì
üé® Animation Player               üöó Robot Moves
  ‚Üì
LED Matrix (Mouth, Eyes)
```

## –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã

### 1. Twist Mux - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∫–æ–º–∞–Ω–¥

**‚ö†Ô∏è Command Node –ù–ï –ø—É–±–ª–∏–∫—É–µ—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ `/cmd_vel`!**

**–ü–æ—Ç–æ–∫**:
```
Command Node ‚Üí Nav2 Action ‚Üí Nav2 Controller ‚Üí /cmd_vel ‚Üí Twist Mux ‚Üí Motors
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã** (`docker/main/config/twist_mux/twist_mux.yaml`):
```yaml
topics:
  - name: emergency_stop
    topic: cmd_vel_emergency
    priority: 255  # HIGHEST
    
  - name: joystick
    topic: cmd_vel_joy
    priority: 100  # HIGH (blocks Nav2!)
    
  - name: web_ui
    topic: cmd_vel_web
    priority: 50
    
  - name: navigation
    topic: cmd_vel
    priority: 10   # LOWEST (autonomous)
```

**–õ–æ–≥–∏–∫–∞**:
- –î–∂–æ–π—Å—Ç–∏–∫ –∞–∫—Ç–∏–≤–µ–Ω ‚Üí Nav2 –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è
- –î–∂–æ–π—Å—Ç–∏–∫ timeout (0.5s) ‚Üí Nav2 –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è
- Emergency stop ‚Üí –≤—Å–µ –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è

### 2. Audio-Reactive Animations

**–†–æ—Ç —Ä–æ–±–æ—Ç–∞ –¥–≤–∏–≥–∞–µ—Ç—Å—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å —Ä–µ—á—å—é!**

**–ü–æ—Ç–æ–∫**:
```
TTS ‚Üí Audio Output ‚Üí PyAudio Loopback ‚Üí RMS Volume ‚Üí /audio/level ‚Üí Frame Selection ‚Üí LED Matrix
```

**–ú–µ—Ö–∞–Ω–∏–∑–º**:
1. `audio_reactive_animation_node` –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –≤—ã—Ö–æ–¥ (loopback)
2. –í—ã—á–∏—Å–ª—è–µ—Ç RMS –≥—Ä–æ–º–∫–æ—Å—Ç—å (0.0-1.0)
3. –ü—É–±–ª–∏–∫—É–µ—Ç –≤ `/audio/level`
4. `animation_player_node` –≤—ã–±–∏—Ä–∞–µ—Ç –∫–∞–¥—Ä: `frame_index = int(audio_level * 11)`
5. LED –º–∞—Ç—Ä–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∫–∞–¥—Ä (—Ä–æ—Ç –æ—Ç–∫—Ä—ã—Ç/–∑–∞–∫—Ä—ã—Ç)

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è** (`animations/manifests/talking.yaml`):
```yaml
mouth_panel:
  audio_controlled: true  # –í–ê–ñ–ù–û!
  frames:
    - frame_0.png   # –†–æ—Ç –∑–∞–∫—Ä—ã—Ç (silence)
    - frame_1.png
    ...
    - frame_11.png  # –†–æ—Ç –æ—Ç–∫—Ä—ã—Ç (loud)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç**: –≠—Ñ—Ñ–µ–∫—Ç "–≥–æ–≤–æ—Ä—è—â–µ–≥–æ —Ä–æ–±–æ—Ç–∞" (–∫–∞–∫ Bender –∏–∑ Futurama)

### 3. –≠–º–æ—Ü–∏–∏ –≤ DeepSeek –æ—Ç–≤–µ—Ç–∞—Ö

**–§–æ—Ä–º–∞—Ç** (`prompts/master_prompt_simple.txt`):
```json
{
  "chunk": 1,
  "ssml": "<speak>–¢–µ–∫—Å—Ç</speak>",
  "emotion": "happy"  ‚Üê –ü–æ–ª–µ —ç–º–æ—Ü–∏–∏
}
```

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —ç–º–æ—Ü–∏–∏**:
- `neutral` - –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
- `happy` - –†–∞–¥–æ—Å—Ç—å
- `sad` - –ì—Ä—É—Å—Ç—å
- `thinking` - –†–∞–∑–º—ã—à–ª–µ–Ω–∏–µ
- `alert` - –¢—Ä–µ–≤–æ–≥–∞
- `angry` - –ó–ª–æ—Å—Ç—å
- `surprised` - –£–¥–∏–≤–ª–µ–Ω–∏–µ

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ**: DeepSeek –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–æ—Ü–∏–∏, –Ω–æ `dialogue_node` –∏—Ö –ø–æ–∫–∞ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç.

**TODO (Phase 6)**: –î–æ–±–∞–≤–∏—Ç—å –≤ `dialogue_node`:
```python
def dialogue_callback(self, msg: String):
    chunk_data = json.loads(msg.data)
    
    # –¢–µ–∫—É—â–µ–µ
    ssml = chunk_data['ssml']
    self.response_pub.publish(...)
    
    # TODO
    if 'emotion' in chunk_data:
        emotion = chunk_data['emotion']
        # –¢—Ä–∏–≥–≥–µ—Ä –∞–Ω–∏–º–∞—Ü–∏–∏
        anim_msg = String()
        anim_msg.data = emotion  # "happy", "sad", etc.
        self.animation_trigger_pub.publish(anim_msg)
        
        # –¢—Ä–∏–≥–≥–µ—Ä –∑–≤—É–∫–∞
        sound_msg = String()
        sound_msg.data = self._emotion_to_sound(emotion)  # "cute", "angry_1"
        self.sound_trigger_pub.publish(sound_msg)
```

**Mapping** (–∏–∑ Phase 4):
```python
emotion_to_sound = {
    'happy': ['cute', 'very_cute'],
    'angry': ['angry_1', 'angry_2'],
    'thinking': ['thinking'],
    'surprised': ['surprise'],
    'sad': ['confused']
}

emotion_to_animation = {
    'happy': 'happy',        # animations/manifests/happy.yaml
    'angry': 'angry',        # animations/manifests/angry.yaml
    'thinking': 'thinking',  # animations/manifests/thinking.yaml
    'surprised': 'surprised',
    'sad': 'sad',
    'neutral': 'eyes_neutral'
}
```

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º

### Voice Command ‚Üí Robot Motion (end-to-end)

**–°—Ü–µ–Ω–∞—Ä–∏–π**: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç "–î–≤–∏–≥–∞–π—Å—è –∫ —Ç–æ—á–∫–µ —Ç—Ä–∏"

1. **Audio Node**: –ó–∞—Ö–≤–∞—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ ‚Üí `/voice/audio/recording`
2. **STT Node**: Vosk ‚Üí "–¥–≤–∏–≥–∞–π—Å—è –∫ —Ç–æ—á–∫–µ —Ç—Ä–∏" ‚Üí `/voice/stt/result`
3. **Command Node**: 
   - Regex: Intent=NAVIGATE, waypoint="—Ç–æ—á–∫–∞ 3"
   - Lookup: `{x: 3.0, y: 0.0, theta: 0.0}`
   - Send Nav2 Goal: `NavigateToPose(x=3.0, y=0.0)`
   - Feedback: "–ò–¥—É –∫ —Ç–æ—á–∫–∞ 3" ‚Üí `/voice/command/feedback`
4. **Dialogue Node**: –ü–æ–ª—É—á–∞–µ—Ç feedback ‚Üí –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ TTS
5. **TTS Node**: Silero ‚Üí "–ò–¥—É –∫ —Ç–æ—á–∫–∞ 3" ‚Üí –∞—É–¥–∏–æ –≤—ã—Ö–æ–¥
6. **Audio Reactive Node**: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ ‚Üí `/audio/level` (0.0-1.0)
7. **Animation Player**: –í—ã–±–æ—Ä –∫–∞–¥—Ä–∞ ‚Üí LED —Ä–æ—Ç –¥–≤–∏–≥–∞–µ—Ç—Å—è
8. **Nav2 Stack**:
   - Planner: A* –ø—É—Ç—å –Ω–∞ –∫–∞—Ä—Ç–µ
   - Controller: DWB –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–∞–Ω–¥—ã —Å–∫–æ—Ä–æ—Å—Ç–∏
   - Publishes: `/cmd_vel` (Twist)
9. **Twist Mux**:
   - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã (–¥–∂–æ–π—Å—Ç–∏–∫ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω)
   - –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç Nav2 –∫–æ–º–∞–Ω–¥—ã ‚Üí `/diff_cont/cmd_vel_unstamped`
10. **ros2_control**: Differential drive ‚Üí VESC –º–æ—Ç–æ—Ä—ã
11. **–†–æ–±–æ—Ç –µ–¥–µ—Ç –∫ —Ç–æ—á–∫–µ (3.0, 0.0), —Ä–æ—Ç –¥–≤–∏–≥–∞–µ—Ç—Å—è –ø—Ä–∏ —Ä–µ—á–∏**
12. **Nav2 Result**: SUCCESS ‚Üí Feedback: "–ü—Ä–∏–±—ã–ª –≤ —Ç–æ—á–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è"
13. **TTS –≥–æ–≤–æ—Ä–∏—Ç "–ü—Ä–∏–±—ã–ª..." ‚Üí —Ä–æ—Ç –¥–≤–∏–≥–∞–µ—Ç—Å—è —Å–Ω–æ–≤–∞**

### –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–∂–æ–π—Å—Ç–∏–∫–æ–º

**–°—Ü–µ–Ω–∞—Ä–∏–π**: –í–æ –≤—Ä–µ–º—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –±–µ—Ä—ë—Ç –¥–∂–æ–π—Å—Ç–∏–∫

1. Nav2 –ø—É–±–ª–∏–∫—É–µ—Ç –≤ `/cmd_vel` (priority 10)
2. Twist Mux –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç ‚Üí —Ä–æ–±–æ—Ç –µ–¥–µ—Ç
3. **–î–∂–æ–π—Å—Ç–∏–∫ –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è**: –ø—É–±–ª–∏–∫—É–µ—Ç –≤ `/cmd_vel_joy` (priority 100)
4. **Twist Mux –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è**: –±–ª–æ–∫–∏—Ä—É–µ—Ç Nav2, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –¥–∂–æ–π—Å—Ç–∏–∫
5. **–†–æ–±–æ—Ç –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è**, —Ä—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
6. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—É—Å–∫–∞–µ—Ç –¥–∂–æ–π—Å—Ç–∏–∫ (timeout 0.5s)
7. **Twist Mux –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è**: Nav2 —Å–Ω–æ–≤–∞ –∞–∫—Ç–∏–≤–µ–Ω
8. **–†–æ–±–æ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –Ω–∞–≤–∏–≥–∞—Ü–∏—é**

## –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã

```bash
# 1. –í—Å–µ –ª–∏ –Ω–æ–¥—ã –∑–∞–ø—É—â–µ–Ω—ã?
ros2 node list | grep -E "audio|stt|tts|dialogue|command|sound|animation"

# 2. –ü—É–±–ª–∏–∫—É—é—Ç—Å—è –ª–∏ —Ç–æ–ø–∏–∫–∏?
ros2 topic hz /voice/stt/result           # STT output
ros2 topic hz /voice/command/feedback     # Command feedback
ros2 topic hz /audio/level                # Audio reactive
ros2 topic hz /cmd_vel                    # Nav2 commands
ros2 topic hz /diff_cont/cmd_vel_unstamped # Final motor commands

# 3. Twist Mux –±–ª–æ–∫–∏—Ä—É–µ—Ç Nav2?
ros2 topic hz /cmd_vel_joy   # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å 0 Hz –¥–ª—è —Ä–∞–±–æ—Ç—ã Nav2

# 4. Nav2 —Ä–∞–±–æ—Ç–∞–µ—Ç?
ros2 action list | grep navigate_to_pose
ros2 node list | grep -E "controller|planner"

# 5. Audio reactive —Ä–∞–±–æ—Ç–∞–µ—Ç?
ros2 topic echo /audio/level  # –î–æ–ª–∂–Ω–æ –º–µ–Ω—è—Ç—å—Å—è –ø—Ä–∏ –∑–≤—É–∫–µ
```

### –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

| –ü—Ä–æ–±–ª–µ–º–∞ | –ü—Ä–∏—á–∏–Ω–∞ | –†–µ—à–µ–Ω–∏–µ |
|----------|---------|---------|
| –†–æ–±–æ—Ç –Ω–µ –¥–≤–∏–∂–µ—Ç—Å—è | –î–∂–æ–π—Å—Ç–∏–∫ –±–ª–æ–∫–∏—Ä—É–µ—Ç Nav2 | –ü—Ä–æ–≤–µ—Ä–∏—Ç—å `ros2 topic hz /cmd_vel_joy` |
| –†–æ—Ç –Ω–µ –¥–≤–∏–≥–∞–µ—Ç—Å—è | PyAudio –Ω–µ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ | `pactl load-module module-loopback` |
| –ö–æ–º–∞–Ω–¥—ã –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è | Low confidence | –°–Ω–∏–∑–∏—Ç—å `confidence_threshold` |
| –ù–µ—Ç —ç–º–æ—Ü–∏–π | dialogue_node –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç | –î–æ–±–∞–≤–∏—Ç—å emotion handler (Phase 6) |

## –ë—É–¥—É—â–µ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ (Phase 6)

### Emotion Integration

**–î–æ–±–∞–≤–∏—Ç—å –≤ dialogue_node.py**:
```python
self.animation_trigger_pub = self.create_publisher(
    String, '/animations/trigger', 10
)

def dialogue_callback(self, msg: String):
    chunk_data = json.loads(msg.data)
    
    # Existing: TTS
    if 'ssml' in chunk_data:
        self.response_pub.publish(...)
    
    # NEW: Emotion triggers
    if 'emotion' in chunk_data:
        emotion = chunk_data['emotion']
        
        # Trigger animation
        anim_msg = String()
        anim_msg.data = emotion
        self.animation_trigger_pub.publish(anim_msg)
        
        # Trigger sound
        sound = self._map_emotion_to_sound(emotion)
        sound_msg = String()
        sound_msg.data = sound
        self.sound_trigger_pub.publish(sound_msg)
```

### Advanced Navigation

- **Dynamic waypoints**: "–ó–∞–ø–æ–º–Ω–∏ —ç—Ç—É —Ç–æ—á–∫—É –∫–∞–∫ –æ—Ñ–∏—Å"
- **Multi-step paths**: "–ò–¥–∏ –∫ –∫—É—Ö–Ω—è –ø–æ—Ç–æ–º –∫ –≥–æ—Å—Ç–∏–Ω–∞—è"
- **Person following**: "–°–ª–µ–¥—É–π –∑–∞ –º–Ω–æ–π"
- **Object detection**: "–ù–∞–π–¥–∏ –∫—Ä–∞—Å–Ω—ã–π –∫—É–±–∏–∫"

### Natural Language Understanding

- **Replace regex** with ML-based intent classifier
- **RASA NLU** or **spaCy** for better understanding
- **Context awareness**: "–¢–∞–º" ‚Üí resolve to previous location

---

**Status**: ‚úÖ All 8 nodes implemented and integrated  
**Documentation**: Complete architecture with all systems explained  
**Next**: Phase 6 - Emotion Integration + Advanced Features
