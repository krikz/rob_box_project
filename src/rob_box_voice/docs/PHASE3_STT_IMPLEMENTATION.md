# Phase 3: STT (Speech-to-Text) Implementation

## –û–±–∑–æ—Ä

**–°—Ç–∞—Ç—É—Å**: ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (Vosk)  
**–î–∞—Ç–∞**: 2025-10-13  
**–í—ã–±—Ä–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ**: Vosk offline recognition

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### STT Node

**–§–∞–π–ª**: `rob_box_voice/stt_node.py` (217 —Å—Ç—Ä–æ–∫)

**ROS –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å**:
```
Subscribers:
  /audio/audio (AudioData)      - –ê—É–¥–∏–æ –ø–æ—Ç–æ–∫ –æ—Ç audio_node
  /audio/vad (Bool)             - Voice Activity Detection

Publishers:
  /voice/stt/result (String)    - –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
  /voice/stt/partial (String)   - –ß–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–≤–æ –≤—Ä–µ–º—è —Ä–µ—á–∏)
  /voice/stt/state (String)     - –°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–æ–¥—ã (ready/listening/error)
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**:
```yaml
model_path: /models/vosk-model-small-ru-0.22
sample_rate: 16000
vad_timeout: 1.5              # –°–µ–∫—É–Ω–¥—ã —Ç–∏—à–∏–Ω—ã ‚Üí —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
min_speech_duration: 0.5      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ä–µ—á–∏
```

## Vosk Integration

### –í—ã–±–æ—Ä —Ä–µ—à–µ–Ω–∏—è

–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å 3 –≤–∞—Ä–∏–∞–Ω—Ç–∞:
1. **Vosk** ‚úÖ - –í—ã–±—Ä–∞–Ω
   - –°–∫–æ—Ä–æ—Å—Ç—å: 0.5-0.67s ‚ö°
   - –¢–æ—á–Ω–æ—Å—Ç—å: 7-8/10 üëç
   - Offline: ‚úÖ
   - CPU: –ù–∏–∑–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
   - –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: 45 MB

2. **Whisper** ‚ùå - –û—Ç–∫–ª–æ–Ω–µ–Ω
   - –°–∫–æ—Ä–æ—Å—Ç—å: 2-5s üêå
   - –¢–æ—á–Ω–æ—Å—Ç—å: 9/10 üåü
   - CPU: –í—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
   - –ü—Ä–æ–±–ª–µ–º—ã —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏

3. **Yandex** ‚ö†Ô∏è - –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
   - –°–∫–æ—Ä–æ—Å—Ç—å: 0.5-1s + —Å–µ—Ç—å
   - –¢–æ—á–Ω–æ—Å—Ç—å: 9/10
   - –¢—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
   - API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–ª–æ–∂–Ω–∞—è

### Vosk Model

**–ú–æ–¥–µ–ª—å**: `vosk-model-small-ru-0.22`  
**–†–∞–∑–º–µ—Ä**: 45 MB  
**–Ø–∑—ã–∫**: –†—É—Å—Å–∫–∏–π  
**–£—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
sudo mkdir -p /models
cd /tmp
wget https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip
unzip vosk-model-small-ru-0.22.zip
sudo mv vosk-model-small-ru-0.22 /models/
```

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã** (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –≤—ã—à–µ —Ç–æ—á–Ω–æ—Å—Ç—å):
- `vosk-model-ru-0.42` - 1.9 GB, —Ç–æ—á–Ω–æ—Å—Ç—å 9/10
- `vosk-model-ru-0.22` - 1.5 GB, —Ç–æ—á–Ω–æ—Å—Ç—å 8.5/10

## –†–∞–±–æ—Ç–∞ STT Node

### –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

1. **–û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ—á–∏**:
   - –°–ª—É—à–∞–µ—Ç `/audio/vad` (Voice Activity Detection)
   - –ö–æ–≥–¥–∞ VAD=True ‚Üí –Ω–∞—á–∞–ª–æ —Ä–µ—á–∏

2. **–ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ**:
   - –ü–æ–ª—É—á–∞–µ—Ç –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫ –∏–∑ `/audio/audio`
   - –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Vosk `recognizer.AcceptWaveform()`
   - –ü—É–±–ª–∏–∫—É–µ—Ç —á–∞—Å—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ `/voice/stt/partial`

3. **–î–µ—Ç–µ–∫—Ü–∏—è –∫–æ–Ω—Ü–∞ —Ñ—Ä–∞–∑—ã**:
   - –ö–æ–≥–¥–∞ VAD=False –Ω–∞ 1.5s ‚Üí –∫–æ–Ω–µ—Ü —Ä–µ—á–∏
   - –ò–ª–∏ Vosk —Å–∞–º –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω–µ—Ü —Ñ—Ä–∞–∑—ã

4. **–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç**:
   - –í—ã–∑–æ–≤ `recognizer.FinalResult()`
   - –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ `/voice/stt/result`
   - –°–±—Ä–æ—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è –¥–ª—è –Ω–æ–≤–æ–π —Ñ—Ä–∞–∑—ã

### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —à—É–º–∞

**–ü—Ä–æ–±–ª–µ–º–∞**: –ö–æ—Ä–æ—Ç–∫–∏–µ –∑–≤—É–∫–∏ (—à–∞–≥–∏, —Å—Ç—É–∫–∏) –º–æ–≥—É—Ç –≤—ã–∑–≤–∞—Ç—å –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è.

**–†–µ—à–µ–Ω–∏–µ**:
```python
if speech_duration < self.min_speech_duration:  # 0.5s
    self.get_logger().info('‚ö†Ô∏è –†–µ—á—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è, –∏–≥–Ω–æ—Ä–∏—Ä—É—é')
    self.reset_recognition()
```

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Dialogue Node

### Data Flow

```
Audio ‚Üí STT ‚Üí Dialogue ‚Üí TTS ‚Üí Speech
  ‚Üì       ‚Üì        ‚Üì         ‚Üì
ReSpeaker ‚Üí Vosk ‚Üí DeepSeek ‚Üí Silero
```

**–¢–æ–ø–∏–∫–∏**:
```
/audio/audio (AudioData)           ‚Üí stt_node
/audio/vad (Bool)                  ‚Üí stt_node
/voice/stt/result (String)         ‚Üí dialogue_node
/voice/dialogue/response (String)  ‚Üí tts_node
/voice/audio/speech (AudioData)    ‚Üí audio_node/speakers
```

### –ü—Ä–∏–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞

1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: **"–ü—Ä–∏–≤–µ—Ç —Ä–æ–±–æ—Ç –∫–∞–∫ –¥–µ–ª–∞"**
   - `audio_node` ‚Üí VAD=True
   - `stt_node` ‚Üí "/voice/stt/result": "–ø—Ä–∏–≤–µ—Ç —Ä–æ–±–æ—Ç –∫–∞–∫ –¥–µ–ª–∞"

2. Dialogue processing:
   - `dialogue_node` ‚Üí DeepSeek API
   - Streaming response: "–ü—Ä–∏–≤–µ—Ç! –£ –º–µ–Ω—è –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ..."

3. TTS synthesis:
   - `tts_node` ‚Üí Silero TTS
   - –° accent_replacer: "–ü—Ä–∏–≤+–µ—Ç! –£ –º–µ–Ω+—è –≤—Å—ë –æ—Ç–ª+–∏—á–Ω–æ..."
   - Chipmunk mode (pitch 2.0x)

4. Audio playback:
   - `audio_node` ‚Üí ReSpeaker 3.5mm jack

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Unit Test Script

**–§–∞–π–ª**: `scripts/test_stt_options.py`

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏**:
- –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ 3 STT –¥–≤–∏–∂–∫–æ–≤
- –ó–∞–ø–∏—Å—å —Å ReSpeaker
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ WAV –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
- –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

**–ó–∞–ø—É—Å–∫**:
```bash
cd src/rob_box_voice/scripts
./quick_start_stt.sh
```

### Integration Test

**TODO**: –°–æ–∑–¥–∞—Ç—å ROS2 integration test:
```bash
ros2 launch rob_box_voice voice_assistant.launch.py
# –ì–æ–≤–æ—Ä–∏—Ç—å –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –ø—Ä–æ–≤–µ—Ä—è—Ç—å:
# - /voice/stt/result - –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
# - /voice/dialogue/response - –æ—Ç–≤–µ—Ç LLM
# - –ê—É–¥–∏–æ –≤—ã—Ö–æ–¥ - —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏
```

## Performance

### –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–∏–∑–º–µ—Ä–µ–Ω–æ –Ω–∞ x86_64)

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –í—Ä–µ–º—è | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è |
|-----------|-------|-------------|
| STT (Vosk) | 0.5-0.7s | ‚úÖ Offline |
| Dialogue (DeepSeek) | 1-2s | ‚úÖ Streaming |
| TTS (Silero) | 0.3-0.5s | ‚úÖ Local |
| **Total** | **1.8-3.2s** | üöÄ Real-time |

### –ù–∞ Raspberry Pi 5 (–æ–∂–∏–¥–∞–µ–º–æ)

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –í—Ä–µ–º—è | –°—Ç–∞—Ç—É—Å |
|-----------|-------|--------|
| STT (Vosk) | ~1s | ‚úÖ OK |
| Dialogue | 1-2s | ‚úÖ Network |
| TTS (Silero) | ~1s | ‚úÖ 4 threads |
| **Total** | **3-4s** | ‚úÖ –ü—Ä–∏–µ–º–ª–µ–º–æ |

### CPU/Memory

```
Vosk Model Load: ~500 MB RAM
Recognition: ~10-20% CPU (1 core)
```

## Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: Vosk –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç

**–ü—Ä–∏—á–∏–Ω—ã**:
1. –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ‚Üí –ü—Ä–æ–≤–µ—Ä–∏—Ç—å `/models/vosk-model-small-ru-0.22`
2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π sample_rate ‚Üí –î–æ–ª–∂–µ–Ω –±—ã—Ç—å 16000 Hz
3. –ü–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ ‚Üí –ü—Ä–æ–≤–µ—Ä–∏—Ç—å ReSpeaker

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**:
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–¥–µ–ª—å
ls -lh /models/vosk-model-small-ru-0.22

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å sample rate
ros2 param get /stt_node sample_rate

# –ó–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π WAV
ros2 topic echo /audio/audio > /tmp/test.raw
```

### –ü—Ä–æ–±–ª–µ–º–∞: –õ–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è

**–†–µ—à–µ–Ω–∏–µ**: –£–≤–µ–ª–∏—á–∏—Ç—å `min_speech_duration`:
```yaml
stt_node:
  min_speech_duration: 0.8  # –±—ã–ª–æ 0.5
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ

**–ü—Ä–∏—á–∏–Ω—ã**:
1. –ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å ‚Üí –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å small –º–æ–¥–µ–ª—å
2. CPU –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω ‚Üí –ü—Ä–æ–≤–µ—Ä–∏—Ç—å `top`
3. Swap –∞–∫—Ç–∏–≤–µ–Ω ‚Üí –£–≤–µ–ª–∏—á–∏—Ç—å RAM

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**:
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `vosk-model-small-ru-0.22` (45 MB)
- –ó–∞–∫—Ä—ã—Ç—å –ª–∏—à–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
- –û—Ç–∫–ª—é—á–∏—Ç—å SWAP –Ω–∞ Pi 5

## Docker Integration

### Dockerfile Updates

**TODO**: –î–æ–±–∞–≤–∏—Ç—å –≤ `docker/vision/Dockerfile`:
```dockerfile
# Vosk STT
RUN pip3 install vosk==0.3.45

# Download Vosk model
RUN mkdir -p /models && \
    cd /models && \
    wget https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip && \
    unzip vosk-model-small-ru-0.22.zip && \
    rm vosk-model-small-ru-0.22.zip
```

### Docker Compose

**–ü—Ä–æ–≤–µ—Ä–∏—Ç—å** –≤ `docker/vision/docker-compose.yaml`:
```yaml
voice-assistant:
  volumes:
    - /models:/models:ro  # Mount Vosk models
```

## Next Steps: Phase 4

**Sound Node** - –∑–≤—É–∫–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã:
- –ó–∞–≥—Ä—É–∑–∫–∞ `.mp3` –∏–∑ `sound_pack/`
- –¢—Ä–∏–≥–≥–µ—Ä—ã –Ω–∞ —Å–æ–±—ã—Ç–∏—è (thinking, surprise, angry)
- –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –∞–Ω–∏–º–∞—Ü–∏—è–º–∏

**TODO**:
1. –°–æ–∑–¥–∞—Ç—å `sound_node.py`
2. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å `sound_pack/` (10 —Ñ–∞–π–ª–æ–≤)
3. –î–æ–±–∞–≤–∏—Ç—å trigger –≤ dialogue_node
4. –û–±–Ω–æ–≤–∏—Ç—å LED –ø–∞—Ç—Ç–µ—Ä–Ω—ã

## References

- [Vosk Documentation](https://alphacephei.com/vosk/)
- [Vosk Python API](https://github.com/alphacep/vosk-api/tree/master/python)
- [Vosk Models](https://alphacephei.com/vosk/models)
- [Phase 3 Testing Guide](PHASE3_STT_TESTING.md)

---

**Status**: ‚úÖ Phase 3 Complete  
**Next**: Phase 4 - Sound Effects Node
