services:
  # Zenoh Router - локальный роутер для Vision Pi, подключается к Main Pi
  # Namespace НЕ используется здесь - он добавляется только на Main Pi при отправке в облако
  zenoh-router:
    image: eclipse/zenoh:latest
    container_name: zenoh-router-vision
    network_mode: host
    environment:
      - RUST_LOG=zenoh=info
    volumes:
      - ./config/zenoh_router_config.json5:/zenoh_config.json5
    command: -c /zenoh_config.json5
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8000/@/local/router || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 20
      start_period: 30s
    labels:
      logging: "promtail"

  oak-d:
    image: ${SERVICE_IMAGE_PREFIX:-ghcr.io/krikz/rob_box}:oak-d-${ROS_DISTRO:-humble}-${IMAGE_TAG:-latest}
    container_name: oak-d
    network_mode: host
    privileged: true
    environment:
      - ROS_DOMAIN_ID=0
      - DISPLAY=:0
      - RMW_IMPLEMENTATION=rmw_zenoh_cpp
      - ROBOT_ID=${ROBOT_ID}  # Для генерации namespace
      - ZENOH_ROUTER_CHECK_ATTEMPTS=10  # Пытаемся подключиться к router 10 раз
      - RUST_LOG=zenoh=info  # Логирование Zenoh для отладки
      # Zenoh configuration через JSON - подключение к ЛОКАЛЬНОМУ роутеру Vision Pi
      - ROS_AUTOMATIC_DISCOVERY_RANGE=LOCALHOST
      - ZENOH_SESSION_CONFIG_URI=/tmp/zenoh_session_config.json5  # Сгенерированный конфиг
      - LD_LIBRARY_PATH=/opt/ros/humble/opt/zenoh_cpp_vendor/lib:/opt/ros/humble/lib/aarch64-linux-gnu:/opt/ros/humble/lib
    volumes:
      - ./config:/config:ro
      - ./scripts:/ros_scripts:ro
      - ./scripts/oak-d:/scripts:ro
      - ./oak-d/launch:/oak-d/launch:ro
      - /dev/bus/usb:/dev/bus/usb
      - /dev/shm:/dev/shm
    # AprilTag-only mode: OAK-D publishes only color image and camera_info for marker detection
    mem_limit: 6g  # Максимум 6GB (оставляем 2GB для системы)
    memswap_limit: 7g  # 6GB RAM + 1GB swap максимум
    command: ["/ros_scripts/ros_with_namespace.sh", "/scripts/start_oak_d.sh"]
    depends_on:
      - zenoh-router
    restart: unless-stopped
    labels:
      logging: "promtail"

  apriltag:
    image: ${SERVICE_IMAGE_PREFIX:-ghcr.io/krikz/rob_box}:apriltag-${ROS_DISTRO:-humble}-${IMAGE_TAG:-latest}
    container_name: apriltag
    network_mode: host
    environment:
      - ROS_DOMAIN_ID=0
      - RMW_IMPLEMENTATION=rmw_zenoh_cpp
      - ROBOT_ID=${ROBOT_ID}  # Для генерации namespace
      - ZENOH_ROUTER_CHECK_ATTEMPTS=10
      - RUST_LOG=zenoh=info
      # Zenoh configuration через JSON - подключение к ЛОКАЛЬНОМУ роутеру Vision Pi
      - ROS_AUTOMATIC_DISCOVERY_RANGE=LOCALHOST
      - ZENOH_SESSION_CONFIG_URI=/tmp/zenoh_session_config.json5  # Сгенерированный конфиг
    volumes:
      - ./config:/config:ro
      - ./scripts:/ros_scripts:ro
      - ./scripts/apriltag:/scripts:ro
      - /dev/shm:/dev/shm
    command: ["/ros_scripts/ros_with_namespace.sh", "/scripts/start_apriltag.sh"]
    depends_on:
      - zenoh-router
      - oak-d
    restart: unless-stopped
    labels:
      logging: "promtail"

  led-matrix:
    image: ${SERVICE_IMAGE_PREFIX:-ghcr.io/krikz/rob_box}:led-matrix-${ROS_DISTRO:-humble}-${IMAGE_TAG:-latest}
    container_name: led-matrix
    network_mode: host
    privileged: true  # Для доступа к SPI (/dev/spidev0.0)
    devices:
      - /dev/spidev0.0:/dev/spidev0.0  # SPI для NeoPixel LED
    environment:
      - ROS_DOMAIN_ID=0
      - RMW_IMPLEMENTATION=rmw_zenoh_cpp
      - ROBOT_ID=${ROBOT_ID}  # Для генерации namespace
      - ZENOH_ROUTER_CHECK_ATTEMPTS=10
      - RUST_LOG=zenoh=info
      - ROS_AUTOMATIC_DISCOVERY_RANGE=LOCALHOST
      - ZENOH_SESSION_CONFIG_URI=/tmp/zenoh_session_config.json5  # Сгенерированный конфиг
    volumes:
      - ./config:/config:ro
      - ./scripts:/ros_scripts:ro
      - ./scripts/led_matrix:/scripts:ro
    command: ["/ros_scripts/ros_with_namespace.sh", "/scripts/start_led_matrix.sh"]
    depends_on:
      - zenoh-router
    restart: unless-stopped
    labels:
      logging: "promtail"

  voice-assistant:
    # Image tags automatically determined by IMAGE_TAG environment variable:
    # - IMAGE_TAG=latest  → voice-assistant-humble-latest (main branch)
    # - IMAGE_TAG=dev     → voice-assistant-humble-dev (develop branch)
    # - IMAGE_TAG=test    → voice-assistant-humble-test (feature/* branches)
    # Built via GitHub Actions: .github/workflows/build-vision-services.yml
    image: ${SERVICE_IMAGE_PREFIX:-ghcr.io/krikz/rob_box}:voice-assistant-${ROS_DISTRO:-humble}-${IMAGE_TAG:-latest}
    container_name: voice-assistant
    network_mode: host
    privileged: true  # Для доступа к USB audio и ReSpeaker
    devices:
      - /dev/snd:/dev/snd  # ALSA audio devices
      - /dev/bus/usb:/dev/bus/usb  # USB для ReSpeaker
    environment:
      - ROS_DOMAIN_ID=0
      - ROS_DISTRO=humble  # Для source /opt/ros/$ROS_DISTRO/setup.bash
      - RMW_IMPLEMENTATION=rmw_zenoh_cpp
      - ZENOH_ROUTER_CHECK_ATTEMPTS=10
      - RUST_LOG=zenoh=info
      - ROS_AUTOMATIC_DISCOVERY_RANGE=LOCALHOST
      - ROBOT_ID=${ROBOT_ID}  # Для генерации namespace
      - ZENOH_SESSION_CONFIG_URI=/tmp/zenoh_session_config.json5  # Сгенерированный конфиг
      # Audio settings
      - ALSA_CARD=ReSpeaker
      - TTS_CACHE_DIR=/cache/tts
      # Python для audio
      - PYTHONUNBUFFERED=1
    env_file:
      - .env.secrets  # API keys: DEEPSEEK_API_KEY, YANDEX_API_KEY, YANDEX_FOLDER_ID
    volumes:
      - ./config:/config:ro
      - ./scripts:/ros_scripts:ro
      - ./scripts/voice:/scripts:ro
      - /dev/shm:/dev/shm
      # Кэш для TTS (persistent)
      - ./cache/tts:/cache/tts
      # Sound pack
      - ../../sound_pack:/ws/sound_pack:ro
    mem_limit: 2g  # Voice Assistant + Animations
    memswap_limit: 2.5g
    command: ["/ros_scripts/ros_with_namespace.sh", "/scripts/start_voice_assistant.sh"]
    depends_on:
      - zenoh-router
    restart: unless-stopped
    labels:
      logging: "promtail"

  # ============ Monitoring Agents ============
  # Агенты мониторинга для Vision Pi
  # Отправляют метрики и логи на отдельную машину мониторинга
  # Можно отключить через: docker-compose --profile monitoring up -d

  # cAdvisor - мониторинг контейнеров (CPU, память, сеть)
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: cadvisor-vision
    profiles: ["monitoring"]
    network_mode: host
    privileged: true
    devices:
      - /dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    command:
      - '--port=8080'
      - '--housekeeping_interval=30s'
      - '--docker_only=true'
      - '--store_container_labels=false'
    restart: unless-stopped

  # Promtail - сбор логов из Docker контейнеров и отправка на машину мониторинга
  promtail:
    image: grafana/promtail:2.9.2
    container_name: promtail-vision
    profiles: ["monitoring"]
    network_mode: host
    environment:
      - LOKI_HOST=${LOKI_HOST:-monitoring-machine}
    volumes:
      - ./config/monitoring/promtail-config.yaml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/config.yml -config.expand-env=true
    restart: unless-stopped
